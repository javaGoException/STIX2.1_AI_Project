{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c979988e-f3f1-41e3-b81b-eb61a3de5a9c",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "id": "b427a805-bcc8-419e-b038-cf30d7ebe8f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T13:13:25.111049Z",
     "start_time": "2025-06-29T13:13:23.172860Z"
    }
   },
   "source": [
    "import json\n",
    "import ast\n",
    "import os\n",
    "from os import getenv\n",
    "from stix2validator import validate_file, print_results\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from neo4j_graphrag.embeddings import OllamaEmbeddings\n",
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "from neo4j_graphrag.indexes import upsert_vectors\n",
    "from neo4j_graphrag.types import EntityType\n",
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "from neo4j_graphrag.llm import OllamaLLM\n",
    "\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "db_uri = getenv(\"db_uri\")\n",
    "db_name = getenv(\"db_name\")\n",
    "db_username = getenv(\"db_username\")\n",
    "db_password= getenv(\"db_password\")\n",
    "\n",
    "auth = (db_username, db_password)\n",
    "driver = GraphDatabase.driver(uri=db_uri, auth=auth)\n",
    "embedder = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "llm = OllamaLLM(model_name=\"deepseek-r1:1.5b\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "934d2c97-9121-4d66-928d-ec25516a86f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T20:29:33.505882Z",
     "start_time": "2025-06-28T20:25:01.151873Z"
    }
   },
   "source": [
    "#main function to load SDOs\n",
    "def load_sdos(path):\n",
    "    with open(path) as f:\n",
    "        stix_json_data = json.load(f)\n",
    "\n",
    "    stix_objects = [obj for obj in stix_json_data[\"objects\"] if obj[\"type\"] not in (\"relationship\", \"x-mitre-collection\")]\n",
    "\n",
    "    for stix_object in stix_objects:\n",
    "\n",
    "        label = to_pascal_case(stix_object[\"type\"])\n",
    "        object_properties = get_stix_properties_dict(stix_object)\n",
    "\n",
    "        query = f\"\"\"\n",
    "            MERGE (x:SDO:{label} {{id: \"{stix_object[\"id\"]}\"}})\n",
    "            SET x = $properties\n",
    "        \"\"\"\n",
    "\n",
    "        session.run(query, properties=object_properties)\n",
    "\n",
    "\n",
    "#main function to load SROs\n",
    "def load_sros(path):\n",
    "    with open(path) as f:\n",
    "        stix_json_data = json.load(f)\n",
    "\n",
    "    stix_relationships = [rel for rel in stix_json_data[\"objects\"] if rel[\"type\"] in \"relationship\"]\n",
    "\n",
    "    for stix_relationship in stix_relationships:\n",
    "\n",
    "        relationship_name = to_pascal_case(stix_relationship[\"relationship_type\"])\n",
    "        relationship_properties = get_stix_properties_dict(stix_relationship)\n",
    "\n",
    "        query = f\"\"\"\n",
    "            MATCH (sourceObject {{id: \"{stix_relationship[\"source_ref\"]}\"}}), (targetObject {{id: \"{stix_relationship[\"target_ref\"]}\"}})\n",
    "            MERGE (sourceObject)-[r:{relationship_name}]->(targetObject)\n",
    "            SET r = $properties\n",
    "        \"\"\"\n",
    "        session.run(query, properties=relationship_properties)\n",
    "\n",
    "\n",
    "#main function to load embedded relationships\n",
    "def load_embedded_relationships(path):\n",
    "    with open(path) as f:\n",
    "        stix_json_data = json.load(f)\n",
    "\n",
    "    ###Matrices to Tactics###\n",
    "\n",
    "    matrix_objects = [obj for obj in stix_json_data[\"objects\"] if obj[\"type\"] == \"x-mitre-matrix\"]\n",
    "\n",
    "    for matrix_obj in matrix_objects:\n",
    "\n",
    "        for tactic_ref_id in matrix_obj[\"tactic_refs\"]:\n",
    "\n",
    "            relationship_type = \"ReferencesTactic\"\n",
    "\n",
    "            relationship_properties = {\n",
    "                \"relationship_type\": relationship_type,\n",
    "                \"source_ref\": matrix_obj[\"id\"],\n",
    "                \"target_ref\": tactic_ref_id\n",
    "            }\n",
    "\n",
    "            query = f\"\"\"\n",
    "                MATCH (sourceObject {{id: \"{matrix_obj[\"id\"]}\"}}), (targetObject {{id: \"{tactic_ref_id}\"}})\n",
    "                MERGE (sourceObject)-[r:{relationship_type}]->(targetObject)\n",
    "                SET r = $properties\n",
    "            \"\"\"\n",
    "            session.run(query, properties=relationship_properties)\n",
    "\n",
    "    ###Tactics to Techniques###\n",
    "\n",
    "    tactic_shortname_to_id = {}\n",
    "    for obj in stix_json_data[\"objects\"]:\n",
    "        if obj[\"type\"] == \"x-mitre-tactic\" and \"x_mitre_shortname\" in obj:\n",
    "            tactic_shortname_to_id[obj[\"x_mitre_shortname\"]] = obj[\"id\"]\n",
    "\n",
    "    attack_patterns = [obj for obj in stix_json_data[\"objects\"] if obj[\"type\"] == \"attack-pattern\"]\n",
    "\n",
    "    for attack_pattern in attack_patterns:\n",
    "        attack_pattern_id = attack_pattern[\"id\"]\n",
    "\n",
    "        if attack_pattern.get(\"kill_chain_phases\"):\n",
    "            for phase in attack_pattern[\"kill_chain_phases\"]:\n",
    "                phase_name = phase[\"phase_name\"]\n",
    "\n",
    "                if phase_name in tactic_shortname_to_id:\n",
    "                    tactic_id = tactic_shortname_to_id[phase_name]\n",
    "\n",
    "                    relationship_type = \"ContainsTechnique\"\n",
    "\n",
    "                    relationship_properties = {\n",
    "                        \"relationship_type\": relationship_type,\n",
    "                        \"source_ref\": tactic_id,\n",
    "                        \"target_ref\": attack_pattern_id,\n",
    "                        \"kill_chain_name\": phase.get(\"kill_chain_name\")\n",
    "                    }\n",
    "\n",
    "                    query = f\"\"\"\n",
    "                            MATCH (sourceObject {{id: \"{tactic_id}\"}}), (targetObject {{id: \"{attack_pattern_id}\"}})\n",
    "                            MERGE (sourceObject)-[r:{relationship_type}]->(targetObject)\n",
    "                            SET r = $properties\n",
    "                        \"\"\"\n",
    "                    session.run(query, properties=relationship_properties)\n",
    "\n",
    "\n",
    "def to_pascal_case(input_string):\n",
    "  words = input_string.split('-')\n",
    "  pascal_case_string = \"\".join(word.capitalize() for word in words)\n",
    "\n",
    "  return pascal_case_string\n",
    "\n",
    "\n",
    "def get_stix_properties_dict(stix_dict):\n",
    "\n",
    "    properties = {}\n",
    "    for attr, value in stix_dict.items():\n",
    "        if isinstance(value, (dict, list)):\n",
    "            properties[attr] = json.dumps(value)\n",
    "        else:\n",
    "            properties[attr] = value\n",
    "\n",
    "    return properties\n",
    "\n",
    "\n",
    "def load_stix_to_neo4j(path: str):\n",
    "    #results = validate_file(path)\n",
    "    #print_results(results)\n",
    "    load_sdos(path)\n",
    "    load_sros(path)\n",
    "    load_embedded_relationships(path)\n",
    "\n",
    "\n",
    "with (driver.session(database=db_name) as session):\n",
    "    load_stix_to_neo4j(\"../attack-stix-data/ics-attack-17.1.json\")\n",
    "    load_stix_to_neo4j(\"../attack-stix-data/mobile-attack-17.1.json\")\n",
    "    load_stix_to_neo4j(\"../attack-stix-data/enterprise-attack-17.1.json\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c20ed765-fa41-449b-83c7-9e6cf7fd6aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T20:29:39.326120Z",
     "start_time": "2025-06-28T20:29:39.307758Z"
    }
   },
   "source": [
    "create_vector_index(\n",
    "    driver,\n",
    "    name=\"nodes\",\n",
    "    label=\"SDO\",\n",
    "    embedding_property=\"embedding\",\n",
    "    dimensions=768,\n",
    "    similarity_fn=\"cosine\",\n",
    "    neo4j_database=db_name\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "0b5669b1-afe3-401d-ba88-e2a8668b320c",
   "metadata": {},
   "source": [
    "with (driver.session(database=db_name) as session):\n",
    "    \n",
    "    result = session.run(\"\"\"\n",
    "    MATCH (n:SDO)\n",
    "    WHERE n.name IS NOT NULL AND n.description IS NOT NULL\n",
    "    OPTIONAL MATCH (n)-[r]->(m)\n",
    "    RETURN n, collect({type: type(r), target: m.name}) AS relationships\n",
    "    \"\"\")\n",
    "\n",
    "    for record in result:\n",
    "        node = record[\"n\"]\n",
    "        relationships = record[\"relationships\"]\n",
    "\n",
    "        base_text = f\"{node['name']}. {node['description']}\"\n",
    "\n",
    "        if relationships:\n",
    "            rel_text = \". \".join(\n",
    "                [f\"Related to {rel['target']} via {rel['type']}\" for rel in relationships if rel[\"target\"]]\n",
    "            )\n",
    "            full_text = f\"{base_text}. {rel_text}\"\n",
    "        else:\n",
    "            full_text = base_text\n",
    "\n",
    "        vector = embedder.embed_query(full_text)\n",
    "\n",
    "        upsert_vectors(\n",
    "            driver,\n",
    "            ids=[node.element_id],\n",
    "            embedding_property=\"embedding\",\n",
    "            embeddings=[vector],\n",
    "            entity_type=EntityType.NODE,\n",
    "            neo4j_database=db_name\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad125991-b142-4b39-bbed-d3b7a0a7aedd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T13:13:41.812078Z",
     "start_time": "2025-06-29T13:13:41.805554Z"
    }
   },
   "source": [
    "def get_neighborhood(driver, node_id):\n",
    "    with (driver.session(database=db_name) as session):\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]-(m)\n",
    "            WHERE n.id = $id\n",
    "            RETURN DISTINCT m, type(r) AS rel_type, r.description AS rel_desc\n",
    "        \"\"\", id=node_id)\n",
    "        return [(record[\"m\"], record[\"rel_type\"], record[\"rel_desc\"]) for record in result]\n",
    "\n",
    "def build_question_context(main_node, neighbors):\n",
    "    parts = []\n",
    "\n",
    "    parts.append(\"Best similarity search (the main node) is: \" + f\"\"\"\"{main_node.get('name')}\" of type \"{main_node.get('type')}\". Description of \"{main_node.get('name')}\": {main_node.get('description')}\"\"\")\n",
    "    parts.append(\"\\nThe main node's neighbors are the following nodes:\")\n",
    "    \n",
    "    for neighbor, rel_type, rel_desc in neighbors:\n",
    "        parts.append(f\"\"\"\n",
    "+++++ {neighbor.get('name').upper()} +++++\\n\n",
    "Node \"{neighbor.get('name')}\" of type \"{neighbor.get('type')}\". Description of \"{neighbor.get('name')}\": {neighbor.get('description')}\\n\n",
    "The main node is related to \"{neighbor.get('name')}\" via type \"{rel_type}\". This relationship contains the following description: {rel_desc}\"\"\")\n",
    "\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "def approach2(query_text):\n",
    "    #query_text = \"What are the names of 2 attack patterns used by WannaCry malware?\"\n",
    "    \n",
    "    retriever = VectorRetriever(driver, \"nodes\", embedder, neo4j_database=db_name)\n",
    "    result = retriever.search(query_text=query_text, top_k=1) #similarity search to get the closest match based on the query_text\n",
    "    \n",
    "    if result.items == []:\n",
    "        raise ValueError(\"Expected items, but got None\")\n",
    "\n",
    "    question_context = \"\"\n",
    "    for item in result.items:\n",
    "        dict_item = ast.literal_eval(item.content)\n",
    "    \n",
    "        #getting neighbours of the closest match node and saving their info to question_context\n",
    "        neighbors_of_main_item = get_neighborhood(driver, dict_item[\"id\"])\n",
    "        question_context += build_question_context(dict_item, neighbors_of_main_item)\n",
    "    \n",
    "    print(f\"\"\"DEBUG question_context:\\n{question_context}\\n{\"#\" * 50}\"\"\")\n",
    "    print(f\"\"\"Question: {query_text}\\n\"\"\")\n",
    "    \n",
    "    # asking llm the question, but now with question_context from the graph\n",
    "    response = llm.invoke(\n",
    "        input=query_text,\n",
    "        system_instruction=question_context\n",
    "    )\n",
    "    print(f\"\"\"Response:\\n{response.content}\"\"\")\n",
    "    return response.content.split(\"</think>\")[1]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "057b7dcc-c677-4d50-b160-0b8a65a3fc5c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "ffbabb65-d3eb-4c44-987a-e3e01de7f24f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "with open(\n",
    "        \"../AttackSeq-Technique-Test.csv\", mode=\"r\", newline=\"\", encoding=\"utf-8\"\n",
    ") as infile, open(\"../approach2.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = [\"Question ID\", \"Answer\", \"Latency\"]\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        question_id = row.get(\"Question ID\", \"\")\n",
    "        question_text = row.get(\"Question\", \"\")\n",
    "\n",
    "        print(f\"---------- {question_id} ----------\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        answer = approach2(question_text)\n",
    "        latency = round(time.time() - start_time, 4)\n",
    "\n",
    "        writer.writerow({\n",
    "            \"Question ID\": question_id,\n",
    "            \"Answer\": answer,\n",
    "            \"Latency\": latency\n",
    "        })\n",
    "        \n",
    "driver.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import csv\n",
    "import time\n",
    "import ast\n",
    "# from neo4j import GraphDatabase\n",
    "# from neo4j_graphrag.embeddings import OllamaEmbeddings\n",
    "# from neo4j_graphrag.retrievers import VectorRetriever\n",
    "# from neo4j_graphrag.llm import OllamaLLM\n",
    "\n",
    "# driver = GraphDatabase.driver(...)\n",
    "# embedder = OllamaEmbeddings(...)\n",
    "# llm = OllamaLLM(...)\n",
    "# db_name = \"...\"\n",
    "\n",
    "def get_neighborhood(driver, node_id):\n",
    "\n",
    "    with (driver.session(database=db_name) as session):\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]-(m)\n",
    "            WHERE n.id = $id\n",
    "            RETURN DISTINCT m, type(r) AS rel_type, r.description AS rel_desc\n",
    "        \"\"\", id=node_id)\n",
    "        return [(record[\"m\"], record[\"rel_type\"], record[\"rel_desc\"]) for record in result]\n",
    "\n",
    "def build_question_context(main_node, neighbors):\n",
    "    parts = []\n",
    "    parts.append(\"Best similarity search (the main node) is: \" + f\"\"\"\"{main_node.get('name')}\" of type \"{main_node.get('type')}\". Description of \"{main_node.get('name')}\": {main_node.get('description')}\"\"\")\n",
    "    parts.append(\"\\nThe main node's neighbors are the following nodes:\")\n",
    "\n",
    "    for neighbor, rel_type, rel_desc in neighbors:\n",
    "        parts.append(f\"\"\"\n",
    "+++++ {neighbor.get('name').upper()} +++++\n",
    "Node \"{neighbor.get('name')}\" of type \"{neighbor.get('type')}\". Description of \"{neighbor.get('name')}\": {neighbor.get('description')}\n",
    "The main node is related to \"{neighbor.get('name')}\" via type \"{rel_type}\". This relationship contains the following description: {rel_desc}\"\"\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# Main approach function\n",
    "def evaluate_approach(query_text, add_rag_context=False, add_choices=False, choices=None):\n",
    "\n",
    "    question_context = \"\"\n",
    "    if add_rag_context:\n",
    "        # Initialize VectorRetriever\n",
    "        retriever = VectorRetriever(driver, \"nodes\", embedder, neo4j_database=db_name)\n",
    "        result = retriever.search(query_text=query_text, top_k=1)\n",
    "\n",
    "        if result.items:\n",
    "            for item in result.items:\n",
    "                dict_item = ast.literal_eval(item.content)\n",
    "                neighbors_of_main_item = get_neighborhood(driver, dict_item[\"id\"])\n",
    "                question_context += build_question_context(dict_item, neighbors_of_main_item)\n",
    "        else:\n",
    "            print(f\"Warning: No relevant nodes found for query: '{query_text}'\")\n",
    "\n",
    "    full_query = query_text\n",
    "    if add_choices and choices:\n",
    "        choices_str = \", \".join(choices)\n",
    "        full_query += f\"\\n\\nChoose from the following options: {choices_str}\"\n",
    "\n",
    "    system_instruction = \"\"\n",
    "    if add_rag_context:\n",
    "        system_instruction = question_context\n",
    "        # Instruct the LLM to use the provided context\n",
    "        system_instruction += \"\\n\\nBased on the provided context and the question, please provide the most accurate answer. Start your answer after </think>.\"\n",
    "    else:\n",
    "        system_instruction = \"Please answer the following question. Start your answer after </think>.\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = llm.invoke(\n",
    "        input=full_query,\n",
    "        system_instruction=system_instruction\n",
    "    )\n",
    "    latency = round(time.time() - start_time, 4)\n",
    "\n",
    "    full_response_content = response.content\n",
    "\n",
    "    thinking_part = \"\"\n",
    "    answer_part = full_response_content\n",
    "    if \"</think>\" in full_response_content:\n",
    "        parts = full_response_content.split(\"</think>\", 1)\n",
    "        thinking_part = parts[0].strip()\n",
    "        answer_part = parts[1].strip()\n",
    "\n",
    "    len_thinking = len(thinking_part)\n",
    "    len_answer = len(answer_part)\n",
    "\n",
    "    return answer_part, latency, len_thinking, len_answer\n",
    "\n",
    "# --- Evaluation Script ---\n",
    "\n",
    "# output CSV filenames\n",
    "input_csv_filename = \"../AttackSeq-Technique-Test.csv\"\n",
    "output_csv_filename = \"evaluation_results.csv\"\n",
    "\n",
    "# headers for the output CSV file\n",
    "fieldnames = [\n",
    "    \"Question ID\",\n",
    "    \"Question\",\n",
    "    \"Ground Truth\",\n",
    "    \"Answer LLM (Question Only)\", \"Duration (QO)\", \"Length Thinking (QO)\", \"Length Answer (QO)\", \"Correctness (QO)\",\n",
    "    \"Answer LLM (RAG)\", \"Duration (RAG)\", \"Length Thinking (RAG)\", \"Length Answer (RAG)\", \"Correctness (RAG)\",\n",
    "    \"Answer LLM (Choices)\", \"Duration (Choices)\", \"Length Thinking (Choices)\", \"Length Answer (Choices)\", \"Correctness (Choices)\"\n",
    "]\n",
    "\n",
    "print(f\"Starting evaluation from '{input_csv_filename}'...\")\n",
    "with open(input_csv_filename, mode=\"r\", newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        question_id = row.get(\"Question ID\", \"\")\n",
    "        question_text = row.get(\"Question\", \"\")\n",
    "        ground_truth = row.get(\"Ground Truth\", \"\").strip().lower()\n",
    "\n",
    "        unshuffled_choices_str = row.get(\"Unshuffled Choices\", \"\")\n",
    "        unshuffled_choices = [c.strip() for c in unshuffled_choices_str.split(',')] if unshuffled_choices_str else []\n",
    "\n",
    "        print(f\"\\n---------- {question_id} ----------\")\n",
    "        print(f\"Question: {question_text}\")\n",
    "\n",
    "        results = {\n",
    "            \"Question ID\": question_id,\n",
    "            \"Question\": question_text,\n",
    "            \"Ground Truth\": row.get(\"Ground Truth\", \"\") # Store original ground truth\n",
    "        }\n",
    "\n",
    "        # --- Scenario 1: Question Only ---\n",
    "        answer_qo, latency_qo, len_thinking_qo, len_answer_qo = evaluate_approach(question_text, add_rag_context=False, add_choices=False)\n",
    "        correctness_qo = \"Correct\" if answer_qo.strip().lower() == ground_truth else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Question Only)\": answer_qo,\n",
    "            \"Duration (QO)\": latency_qo,\n",
    "            \"Length Thinking (QO)\": len_thinking_qo,\n",
    "            \"Length Answer (QO)\": len_answer_qo,\n",
    "            \"Correctness (QO)\": correctness_qo\n",
    "        })\n",
    "        print(f\"  [QO] Answer: '{answer_qo}' | Correct: {correctness_qo}\")\n",
    "\n",
    "        # --- Scenario 2: Question + RAG Graph Knowledge ---\n",
    "        answer_rag, latency_rag, len_thinking_rag, len_answer_rag = evaluate_approach(question_text, add_rag_context=True, add_choices=False)\n",
    "        correctness_rag = \"Correct\" if answer_rag.strip().lower() == ground_truth else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (RAG)\": answer_rag,\n",
    "            \"Duration (RAG)\": latency_rag,\n",
    "            \"Length Thinking (RAG)\": len_thinking_rag,\n",
    "            \"Length Answer (RAG)\": len_answer_rag,\n",
    "            \"Correctness (RAG)\": correctness_rag\n",
    "        })\n",
    "        print(f\"  [RAG] Answer: '{answer_rag}' | Correct: {correctness_rag}\")\n",
    "\n",
    "        # --- Scenario 3: Question + RAG Graph Knowledge + Answer Choices ---\n",
    "        answer_choices, latency_choices, len_thinking_choices, len_answer_choices = evaluate_approach(question_text, add_rag_context=True, add_choices=True, choices=unshuffled_choices)\n",
    "        correctness_choices = \"Correct\" if answer_choices.strip().lower() == ground_truth else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Choices)\": answer_choices,\n",
    "            \"Duration (Choices)\": latency_choices,\n",
    "            \"Length Thinking (Choices)\": len_thinking_choices,\n",
    "            \"Length Answer (Choices)\": len_answer_choices,\n",
    "            \"Correctness (Choices)\": correctness_choices\n",
    "        })\n",
    "        print(f\"  [Choices] Answer: '{answer_choices}' | Correct: {correctness_choices}\")\n",
    "\n",
    "        writer.writerow(results)\n",
    "\n",
    "driver.close()\n",
    "print(f\"\\nEvaluation complete. Results saved to '{output_csv_filename}'\")"
   ],
   "id": "8a4b2c4581cc3835"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import csv\n",
    "import time\n",
    "import ast\n",
    "\n",
    "# Annahme: Imports und Initialisierungen bereits vorhanden\n",
    "# from neo4j import GraphDatabase\n",
    "# from neo4j_graphrag.embeddings import OllamaEmbeddings\n",
    "# from neo4j_graphrag.retrievers import VectorRetriever\n",
    "# from neo4j_graphrag.llm import OllamaLLM\n",
    "\n",
    "# Annahme: 'driver', 'embedder', 'llm', 'db_name'  global verfügbar\n",
    "# from os import getenv\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\".env\")\n",
    "# db_uri = getenv(\"db_uri\")\n",
    "# db_name = getenv(\"db_name\")\n",
    "# db_username = getenv(\"db_username\")\n",
    "# db_password = getenv(\"db_password\")\n",
    "# auth = (db_username, db_password)\n",
    "# driver = GraphDatabase.driver(uri=db_uri, auth=auth)\n",
    "# embedder = OllamaEmbeddings(model=\"nomic-embed-text\") # Oder Ihr spezifisches Modell\n",
    "# llm = OllamaLLM(model_name=\"deepseek-r1:1.5b\") # Oder Ihr spezifisches Modell\n",
    "\n",
    "\n",
    "def get_neighborhood(driver, node_id):\n",
    "\n",
    "    with (driver.session(database=db_name) as session):\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]-(m)\n",
    "            WHERE n.id = $id\n",
    "            RETURN DISTINCT m, type(r) AS rel_type, r.description AS rel_desc\n",
    "        \"\"\", id=node_id)\n",
    "        return [(record[\"m\"], record[\"rel_type\"], record[\"rel_desc\"]) for record in result]\n",
    "\n",
    "def build_question_context(main_node, neighbors):\n",
    "\n",
    "    parts = []\n",
    "    parts.append(\"Best similarity search (the main node) is: \" + f\"\"\"\"{main_node.get('name')}\" of type \"{main_node.get('type')}\". Description of \"{main_node.get('name')}\": {main_node.get('description')}\"\"\")\n",
    "    parts.append(\"\\nThe main node's neighbors are the following nodes:\")\n",
    "\n",
    "    for neighbor, rel_type, rel_desc in neighbors:\n",
    "        parts.append(f\"\"\"\n",
    "+++++ {neighbor.get('name').upper()} +++++\n",
    "Node \"{neighbor.get('name')}\" of type \"{neighbor.get('type')}\". Description of \"{neighbor.get('name')}\": {neighbor.get('description')}\n",
    "The main node is related to \"{neighbor.get('name')}\" via type \"{rel_type}\". This relationship contains the following description: {rel_desc}\"\"\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# --- Ende der Funktionen aus Ihrem ursprünglichen Ansatz ---\n",
    "\n",
    "\n",
    "# Haupt-Ansatzfunktion (modifiziert für 3 Szenarien und DEBUG-Ausgabe)\n",
    "def evaluate_approach(query_text, add_rag_context=False, add_choices=False, choices=None):\n",
    "\n",
    "    question_context = \"\"\n",
    "    if add_rag_context:\n",
    "        # Initialisiere VectorRetriever\n",
    "        retriever = VectorRetriever(driver, \"nodes\", embedder, neo4j_database=db_name)\n",
    "        result = retriever.search(query_text=query_text, top_k=1)\n",
    "\n",
    "        if result.items:\n",
    "            for item in result.items:\n",
    "                # item.content wird als String-Repräsentation\n",
    "                dict_item = ast.literal_eval(item.content)\n",
    "                print(f\"DEBUG: Vom Retriever gefundener Knoten (Main Node): {dict_item.get('name')} (ID: {dict_item.get('id')})\")\n",
    "                neighbors_of_main_item = get_neighborhood(driver, dict_item[\"id\"])\n",
    "                question_context += build_question_context(dict_item, neighbors_of_main_item)\n",
    "        else:\n",
    "            print(f\"Warning: Keine relevanten Knoten für die Abfrage gefunden: '{query_text}'\")\n",
    "\n",
    "    full_query = query_text\n",
    "    if add_choices and choices:\n",
    "        choices_str = \", \".join(choices)\n",
    "        full_query += f\"\\n\\nChoose from the following options: {choices_str}\"\n",
    "\n",
    "    system_instruction = \"\"\n",
    "    if add_rag_context:\n",
    "        system_instruction = question_context\n",
    "        # Weist das LLM an\n",
    "        system_instruction += \"\\n\\nBasierend auf dem bereitgestellten Kontext und der Frage, geben Sie bitte die genaueste Antwort. Beginnen Sie Ihre Antwort nach </think>.\"\n",
    "    else:\n",
    "        system_instruction = \"Bitte beantworten Sie die folgende Frage. Beginnen Sie Ihre Antwort nach </think>.\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = llm.invoke(\n",
    "        input=full_query,\n",
    "        system_instruction=system_instruction\n",
    "    )\n",
    "    latency = round(time.time() - start_time, 4)\n",
    "\n",
    "    full_response_content = response.content\n",
    "\n",
    "    # Trenne die Antwort </think>-Token\n",
    "    thinking_part = \"\"\n",
    "    answer_part = full_response_content\n",
    "    if \"</think>\" in full_response_content:\n",
    "        parts = full_response_content.split(\"</think>\", 1)\n",
    "        thinking_part = parts[0].strip()\n",
    "        answer_part = parts[1].strip()\n",
    "\n",
    "    len_thinking = len(thinking_part)\n",
    "    len_answer = len(answer_part)\n",
    "\n",
    "    return answer_part, latency, len_thinking, len_answer\n",
    "\n",
    "# --- Evaluationsskript ---\n",
    "\n",
    "# Definiere die Namen der Input- und Output-CSV-Dateien\n",
    "input_csv_filename = \"../AttackSeq-Technique-Test.csv\"\n",
    "output_csv_filename = \"evaluation_results.csv\"\n",
    "\n",
    "# Definiere die Header für die Output-CSV-Datei\n",
    "fieldnames = [\n",
    "    \"Question ID\",\n",
    "    \"Question\",\n",
    "    \"Ground Truth\",\n",
    "    \"Answer LLM (Question Only)\", \"Duration (QO)\", \"Length Thinking (QO)\", \"Length Answer (QO)\", \"Correctness (QO)\",\n",
    "    \"Answer LLM (RAG)\", \"Duration (RAG)\", \"Length Thinking (RAG)\", \"Length Answer (RAG)\", \"Correctness (RAG)\",\n",
    "    \"Answer LLM (Choices)\", \"Duration (Choices)\", \"Length Thinking (Choices)\", \"Length Answer (Choices)\", \"Correctness (Choices)\"\n",
    "]\n",
    "\n",
    "print(f\"Starte die Evaluation von '{input_csv_filename}'...\")\n",
    "with open(input_csv_filename, mode=\"r\", newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        question_id = row.get(\"Question ID\", \"\")\n",
    "        question_text = row.get(\"Question\", \"\")\n",
    "        ground_truth = row.get(\"Ground Truth\", \"\").strip().lower()\n",
    "\n",
    "        unshuffled_choices_str = row.get(\"Unshuffled Choices\", \"\")\n",
    "        unshuffled_choices = [c.strip() for c in unshuffled_choices_str.split(',')] if unshuffled_choices_str else []\n",
    "\n",
    "        print(f\"\\n---------- {question_id} ----------\")\n",
    "        print(f\"Question: {question_text}\")\n",
    "\n",
    "        results = {\n",
    "            \"Question ID\": question_id,\n",
    "            \"Question\": question_text,\n",
    "            \"Ground Truth\": row.get(\"Ground Truth\", \"\")\n",
    "        }\n",
    "\n",
    "        # --- Szenario 1: Nur Frage ---\n",
    "        answer_qo, latency_qo, len_thinking_qo, len_answer_qo = evaluate_approach(question_text, add_rag_context=False, add_choices=False)\n",
    "        correctness_qo = \"Correct\" if ground_truth in answer_qo.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Question Only)\": answer_qo,\n",
    "            \"Duration (QO)\": latency_qo,\n",
    "            \"Length Thinking (QO)\": len_thinking_qo,\n",
    "            \"Length Answer (QO)\": len_answer_qo,\n",
    "            \"Correctness (QO)\": correctness_qo\n",
    "        })\n",
    "        print(f\"  [QO] Answer: '{answer_qo}' | Correct: {correctness_qo}\")\n",
    "\n",
    "        # --- Szenario 2: Frage + RAG Graph Wissen ---\n",
    "        answer_rag, latency_rag, len_thinking_rag, len_answer_rag = evaluate_approach(question_text, add_rag_context=True, add_choices=False)\n",
    "        correctness_rag = \"Correct\" if ground_truth in answer_rag.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (RAG)\": answer_rag,\n",
    "            \"Duration (RAG)\": latency_rag,\n",
    "            \"Length Thinking (RAG)\": len_thinking_rag,\n",
    "            \"Length Answer (RAG)\": len_answer_rag,\n",
    "            \"Correctness (RAG)\": correctness_rag\n",
    "        })\n",
    "        print(f\"  [RAG] Answer: '{answer_rag}' | Correct: {correctness_rag}\")\n",
    "\n",
    "        # --- Szenario 3: Frage + RAG Graph Wissen + Antwortmöglichkeiten ---\n",
    "        answer_choices, latency_choices, len_thinking_choices, len_answer_choices = evaluate_approach(question_text, add_rag_context=True, add_choices=True, choices=unshuffled_choices)\n",
    "        correctness_choices = \"Correct\" if ground_truth in answer_choices.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Choices)\": answer_choices,\n",
    "            \"Duration (Choices)\": latency_choices,\n",
    "            \"Length Thinking (Choices)\": len_thinking_choices,\n",
    "            \"Length Answer (Choices)\": len_answer_choices,\n",
    "            \"Correctness (Choices)\": correctness_choices\n",
    "        })\n",
    "        print(f\"  [Choices] Answer: '{answer_choices}' | Correct: {correctness_choices}\")\n",
    "\n",
    "        writer.writerow(results)\n",
    "\n",
    "driver.close()\n",
    "print(f\"\\nEvaluation abgeschlossen. Ergebnisse gespeichert in '{output_csv_filename}'\")"
   ],
   "id": "a34446a984961300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import csv\n",
    "import time\n",
    "import ast\n",
    "\n",
    "# from neo4j import GraphDatabase\n",
    "# from neo4j_graphrag.embeddings import OllamaEmbeddings\n",
    "# from neo4j_graphrag.retrievers import VectorRetriever\n",
    "# from neo4j_graphrag.llm import OllamaLLM\n",
    "\n",
    "# Beispiel (falls noch nicht geschehen, ersetzen Sie die Platzhalter):\n",
    "# from os import getenv\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\".env\")\n",
    "# db_uri = getenv(\"db_uri\")\n",
    "# db_name = getenv(\"db_name\")\n",
    "# db_username = getenv(\"db_username\")\n",
    "# db_password = getenv(\"db_password\")\n",
    "# auth = (db_username, db_password)\n",
    "# driver = GraphDatabase.driver(uri=db_uri, auth=auth)\n",
    "# embedder = OllamaEmbeddings(model=\"nomic-embed-text\") # Oder Ihr spezifisches Modell\n",
    "# llm = OllamaLLM(model_name=\"deepseek-r1:1.5b\") # Oder Ihr spezifisches Modell\n",
    "\n",
    "def get_neighborhood(driver, node_id):\n",
    "\n",
    "    with (driver.session(database=db_name) as session):\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]-(m)\n",
    "            WHERE n.id = $id\n",
    "            RETURN DISTINCT m, type(r) AS rel_type, r.description AS rel_desc\n",
    "        \"\"\", id=node_id)\n",
    "        return [(record[\"m\"], record[\"rel_type\"], record[\"rel_desc\"]) for record in result]\n",
    "\n",
    "def build_question_context(main_node, neighbors):\n",
    "\n",
    "    parts = []\n",
    "    parts.append(\"Best similarity search (the main node) is: \" + f\"\"\"\"{main_node.get('name')}\" of type \"{main_node.get('type')}\". Description of \"{main_node.get('name')}\": {main_node.get('description')}\"\"\")\n",
    "    parts.append(\"\\nThe main node's neighbors are the following nodes:\")\n",
    "\n",
    "    for neighbor, rel_type, rel_desc in neighbors:\n",
    "        parts.append(f\"\"\"\n",
    "+++++ {neighbor.get('name').upper()} +++++\n",
    "Node \"{neighbor.get('name')}\" of type \"{neighbor.get('type')}\". Description of \"{neighbor.get('name')}\": {neighbor.get('description')}\n",
    "The main node is related to \"{neighbor.get('name')}\" via type \"{rel_type}\". This relationship contains the following description: {rel_desc}\"\"\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def evaluate_approach(query_text, add_rag_context=False, add_choices=False, choices=None):\n",
    "\n",
    "    question_context = \"\"\n",
    "    found_node_info = \"\"\n",
    "\n",
    "    if add_rag_context:\n",
    "        retriever = VectorRetriever(driver, \"nodes\", embedder, neo4j_database=db_name)\n",
    "        result = retriever.search(query_text=query_text, top_k=1)\n",
    "\n",
    "        if result.items:\n",
    "            for item in result.items:\n",
    "                dict_item = ast.literal_eval(item.content)\n",
    "\n",
    "                found_node_info = f\"DEBUG: Gefundener Knoten (Main Node): Name='{dict_item.get('name')}', Type='{dict_item.get('type')}', ID='{dict_item.get('id')}'\"\n",
    "\n",
    "                neighbors_of_main_item = get_neighborhood(driver, dict_item[\"id\"])\n",
    "                question_context += build_question_context(dict_item, neighbors_of_main_item)\n",
    "        else:\n",
    "            found_node_info = f\"Warning: Keine relevanten Knoten für die Abfrage gefunden: '{query_text}'\"\n",
    "\n",
    "    full_query = query_text\n",
    "    if add_choices and choices:\n",
    "        choices_str = \", \".join(choices)\n",
    "        full_query += f\"\\n\\nChoose from the following options: {choices_str}\"\n",
    "\n",
    "    system_instruction = \"\"\n",
    "    if add_rag_context:\n",
    "        system_instruction = question_context\n",
    "        # Weist das LLM an, den bereitgestellten Kontext zu verwenden\n",
    "        system_instruction += \"\\n\\nAs an IT security expert, based on the provided context and the question, please provide the most accurate answer in English. Start your answer after </think>.\"\n",
    "    else:\n",
    "        # System-Anweisung für den \"Nur Frage\"-Modus\n",
    "        system_instruction = \"You are an IT security expert. Please answer the following question in English. Start your answer after </think>.\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = llm.invoke(\n",
    "        input=full_query,\n",
    "        system_instruction=system_instruction\n",
    "    )\n",
    "    latency = round(time.time() - start_time, 4)\n",
    "\n",
    "    full_response_content = response.content\n",
    "\n",
    "    thinking_part = \"\"\n",
    "    answer_part = full_response_content\n",
    "    if \"</think>\" in full_response_content:\n",
    "        parts = full_response_content.split(\"</think>\", 1)\n",
    "        thinking_part = parts[0].strip()\n",
    "        answer_part = parts[1].strip()\n",
    "\n",
    "    len_thinking = len(thinking_part)\n",
    "    len_answer = len(answer_part)\n",
    "\n",
    "    return answer_part, latency, len_thinking, len_answer, found_node_info\n",
    "\n",
    "\n",
    "# --- Evaluationsskript ---\n",
    "\n",
    "input_csv_filename = \"../AttackSeq-Technique-Test.csv\"\n",
    "output_csv_filename = \"evaluation_results.csv\"\n",
    "\n",
    "fieldnames = [\n",
    "    \"Question ID\",\n",
    "    \"Question\",\n",
    "    \"Ground Truth\",\n",
    "    \"Answer LLM (Question Only)\", \"Duration (QO)\", \"Length Thinking (QO)\", \"Length Answer (QO)\", \"Correctness (QO)\",\n",
    "    \"Answer LLM (RAG)\", \"Duration (RAG)\", \"Length Thinking (RAG)\", \"Length Answer (RAG)\", \"Correctness (RAG)\", \"Found Node RAG\",\n",
    "    \"Answer LLM (Choices)\", \"Duration (Choices)\", \"Length Thinking (Choices)\", \"Length Answer (Choices)\", \"Correctness (Choices)\", \"Found Node Choices\"\n",
    "]\n",
    "\n",
    "print(f\"Starte die Evaluation von '{input_csv_filename}'...\")\n",
    "with open(input_csv_filename, mode=\"r\", newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        question_id = row.get(\"Question ID\", \"\")\n",
    "        question_text = row.get(\"Question\", \"\")\n",
    "        ground_truth = row.get(\"Ground Truth\", \"\").strip().lower()\n",
    "\n",
    "        unshuffled_choices_str = row.get(\"Unshuffled Choices\", \"\")\n",
    "        unshuffled_choices = [c.strip() for c in unshuffled_choices_str.split(',')] if unshuffled_choices_str else []\n",
    "\n",
    "        print(f\"\\n---------- {question_id} ----------\")\n",
    "        print(f\"Question: {question_text}\")\n",
    "\n",
    "        results = {\n",
    "            \"Question ID\": question_id,\n",
    "            \"Question\": question_text,\n",
    "            \"Ground Truth\": row.get(\"Ground Truth\", \"\")\n",
    "        }\n",
    "\n",
    "        # --- Szenario 1: Nur Frage ---\n",
    "        answer_qo, latency_qo, len_thinking_qo, len_answer_qo, _ = evaluate_approach(question_text, add_rag_context=False, add_choices=False)\n",
    "        correctness_qo = \"Correct\" if ground_truth in answer_qo.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Question Only)\": answer_qo,\n",
    "            \"Duration (QO)\": latency_qo,\n",
    "            \"Length Thinking (QO)\": len_thinking_qo,\n",
    "            \"Length Answer (QO)\": len_answer_qo,\n",
    "            \"Correctness (QO)\": correctness_qo\n",
    "        })\n",
    "        print(f\"  [QO] Answer: '{answer_qo}' | Correct: {correctness_qo}\")\n",
    "\n",
    "        # --- Szenario 2: Frage + RAG Graph Wissen ---\n",
    "        answer_rag, latency_rag, len_thinking_rag, len_answer_rag, found_node_rag_info = evaluate_approach(question_text, add_rag_context=True, add_choices=False)\n",
    "        correctness_rag = \"Correct\" if ground_truth in answer_rag.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (RAG)\": answer_rag,\n",
    "            \"Duration (RAG)\": latency_rag,\n",
    "            \"Length Thinking (RAG)\": len_thinking_rag,\n",
    "            \"Length Answer (RAG)\": len_answer_rag,\n",
    "            \"Correctness (RAG)\": correctness_rag,\n",
    "            \"Found Node RAG\": found_node_rag_info\n",
    "        })\n",
    "        print(f\"  [RAG] {found_node_rag_info}\")\n",
    "        print(f\"  [RAG] Answer: '{answer_rag}' | Correct: {correctness_rag}\")\n",
    "\n",
    "        # --- Szenario 3: Frage + RAG Graph Wissen + Antwortmöglichkeiten ---\n",
    "        answer_choices, latency_choices, len_thinking_choices, len_answer_choices, found_node_choices_info = evaluate_approach(question_text, add_rag_context=True, add_choices=True, choices=unshuffled_choices)\n",
    "        correctness_choices = \"Correct\" if ground_truth in answer_choices.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Choices)\": answer_choices,\n",
    "            \"Duration (Choices)\": latency_choices,\n",
    "            \"Length Thinking (Choices)\": len_thinking_choices,\n",
    "            \"Length Answer (Choices)\": len_answer_choices,\n",
    "            \"Correctness (Choices)\": correctness_choices,\n",
    "            \"Found Node Choices\": found_node_choices_info\n",
    "        })\n",
    "        print(f\"  [Choices] {found_node_choices_info}\")\n",
    "        print(f\"  [Choices] Answer: '{answer_choices}' | Correct: {correctness_choices}\")\n",
    "\n",
    "        writer.writerow(results)\n",
    "\n",
    "print(f\"\\nEvaluation abgeschlossen. Ergebnisse gespeichert in '{output_csv_filename}'\")"
   ],
   "id": "1a8e7a41d1549b70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Bestes Skript bisher #####################################################",
   "id": "b41134bef1cca69c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import time\n",
    "import ast\n",
    "\n",
    "# from neo4j import GraphDatabase\n",
    "# from neo4j_graphrag.embeddings import OllamaEmbeddings\n",
    "# from neo4j_graphrag.retrievers import VectorRetriever\n",
    "# from neo4j_graphrag.llm import OllamaLLM\n",
    "\n",
    "# from os import getenv\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\".env\")\n",
    "# db_uri = getenv(\"db_uri\")\n",
    "# db_name = getenv(\"db_name\")\n",
    "# db_username = getenv(\"db_username\")\n",
    "# db_password = getenv(\"db_password\")\n",
    "# auth = (db_username, db_password)\n",
    "# driver = GraphDatabase.driver(uri=db_uri, auth=auth)\n",
    "# embedder = OllamaEmbeddings(model=\"nomic-embed-text\") # Oder Ihr spezifisches Modell\n",
    "# llm = OllamaLLM(model_name=\"deepseek-r1:1.5b\") # Oder Ihr spezifisches Modell\n",
    "\n",
    "\n",
    "def get_neighborhood(driver, node_id):\n",
    "\n",
    "    with (driver.session(database=db_name) as session):\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]-(m)\n",
    "            WHERE n.id = $id\n",
    "            RETURN DISTINCT m, type(r) AS rel_type, r.description AS rel_desc\n",
    "        \"\"\", id=node_id)\n",
    "        # Return the list of neighbors and their count\n",
    "        neighbors = [(record[\"m\"], record[\"rel_type\"], record[\"rel_desc\"]) for record in result]\n",
    "        return neighbors, len(neighbors)\n",
    "\n",
    "def build_question_context(main_node, neighbors):\n",
    "    parts = []\n",
    "    parts.append(\"Best similarity search (the main node) is: \" + f\"\"\"\"{main_node.get('name')}\" of type \"{main_node.get('type')}\". Description of \"{main_node.get('name')}\": {main_node.get('description')}\"\"\")\n",
    "    parts.append(\"\\nThe main node's neighbors are the following nodes:\")\n",
    "\n",
    "    for neighbor, rel_type, rel_desc in neighbors:\n",
    "        parts.append(f\"\"\"\n",
    "+++++ {neighbor.get('name').upper()} +++++\n",
    "Node \"{neighbor.get('name')}\" of type \"{neighbor.get('type')}\". Description of \"{neighbor.get('name')}\": {neighbor.get('description')}\n",
    "The main node is related to \"{neighbor.get('name')}\" via type \"{rel_type}\". This relationship contains the following description: {rel_desc}\"\"\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def evaluate_approach(query_text, add_rag_context=False, add_choices=False, choices=None):\n",
    "\n",
    "    question_context_for_llm_sys_instruction = \"\"\n",
    "    main_retrieved_node_name = \"N/A\"\n",
    "    num_retrieved_neighbors = 0\n",
    "    choices_sent_to_llm = \"N/A\"\n",
    "\n",
    "    if add_rag_context:\n",
    "        retriever = VectorRetriever(driver, \"nodes\", embedder, neo4j_database=db_name)\n",
    "        result = retriever.search(query_text=query_text, top_k=1)\n",
    "\n",
    "        if result.items:\n",
    "            for item in result.items:\n",
    "                dict_item = ast.literal_eval(item.content)\n",
    "                main_retrieved_node_name = dict_item.get('name', 'N/A')\n",
    "\n",
    "                neighbors_of_main_item, num_retrieved_neighbors = get_neighborhood(driver, dict_item[\"id\"])\n",
    "                question_context_for_llm_sys_instruction += build_question_context(dict_item, neighbors_of_main_item)\n",
    "        else:\n",
    "            main_retrieved_node_name = f\"Warning: No relevant nodes found for query: '{query_text}'\"\n",
    "            num_retrieved_neighbors = 0\n",
    "\n",
    "    full_query_to_llm = query_text\n",
    "\n",
    "    if add_choices and choices:\n",
    "        choices_str = \", \".join(choices)\n",
    "        full_query_to_llm += f\"\\n\\nChoose from the following options: {choices_str}\"\n",
    "        choices_sent_to_llm = choices_str\n",
    "\n",
    "    system_instruction = \"\"\n",
    "    if add_rag_context:\n",
    "        system_instruction = question_context_for_llm_sys_instruction\n",
    "        system_instruction += \"\\n\\nAs an IT security expert, based on the provided context and the question, please provide the most accurate answer in English. Start your answer after </think>.\"\n",
    "    else:\n",
    "        system_instruction = \"You are an IT security expert. Please answer the following question in English. Start your answer after </think>.\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = llm.invoke(\n",
    "        input=full_query_to_llm,\n",
    "        system_instruction=system_instruction\n",
    "    )\n",
    "    latency = round(time.time() - start_time, 4)\n",
    "\n",
    "    full_response_content = response.content\n",
    "\n",
    "    thinking_part = \"\"\n",
    "    answer_part = full_response_content\n",
    "    if \"</think>\" in full_response_content:\n",
    "        parts = full_response_content.split(\"</think>\", 1)\n",
    "        thinking_part = parts[0].strip()\n",
    "        answer_part = parts[1].strip()\n",
    "\n",
    "    len_thinking = len(thinking_part)\n",
    "    len_answer = len(answer_part)\n",
    "\n",
    "    display_system_instruction_for_csv = \"As an IT security expert, based on the provided context and the question, please provide the most accurate answer in English. Start your answer after </think>.\"\n",
    "    if not add_rag_context:\n",
    "        display_system_instruction_for_csv = \"You are an IT security expert. Please answer the following question in English. Start your answer after </think>.\"\n",
    "\n",
    "    full_llm_input_combined = f\"System Instruction (simplified for CSV):\\n{display_system_instruction_for_csv}\\n\\nUser Input:\\n{full_query_to_llm}\"\n",
    "\n",
    "\n",
    "    return answer_part, latency, len_thinking, len_answer, full_llm_input_combined, main_retrieved_node_name, num_retrieved_neighbors, choices_sent_to_llm\n",
    "\n",
    "\n",
    "# --- Evaluationsskript ---\n",
    "\n",
    "input_csv_filename = \"AttackSeq-Technique_100.csv\" #best\n",
    "output_csv_filename = \"evaluation_results.csv\"\n",
    "\n",
    "fieldnames = [\n",
    "    \"Question ID\",\n",
    "    \"Question\",\n",
    "    \"Ground Truth\",\n",
    "    \"Answer LLM (QO)\", \"Duration (QO)\", \"Length Thinking (QO)\", \"Length Answer (QO)\", \"Correctness (QO)\", \"LLM Input (QO)\",\n",
    "    \"Answer LLM (RAG)\", \"Duration (RAG)\", \"Length Thinking (RAG)\", \"Length Answer (RAG)\", \"Correctness (RAG)\", \"Main Retrieved Node Name (RAG)\", \"Num Retrieved Neighbors (RAG)\", \"LLM Input (RAG)\",\n",
    "    \"Answer LLM (Choices)\", \"Duration (Choices)\", \"Length Thinking (Choices)\", \"Length Answer (Choices)\", \"Correctness (Choices)\", \"Main Retrieved Node Name (Choices)\", \"Num Retrieved Neighbors (Choices)\", \"LLM Input (Choices)\", \"LLM Choices (Choices)\",\n",
    "    \"Answer LLM (Choices No RAG)\", \"Duration (Choices No RAG)\", \"Length Thinking (Choices No RAG)\", \"Length Answer (Choices No RAG)\", \"Correctness (Choices No RAG)\", \"LLM Input (Choices No RAG)\", \"LLM Choices (Choices No RAG)\"\n",
    "]\n",
    "\n",
    "print(f\"Starte die Evaluation von '{input_csv_filename}'...\")\n",
    "with open(input_csv_filename, mode=\"r\", newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        question_id = row.get(\"Question ID\", \"\")\n",
    "        question_text = row.get(\"Question\", \"\")\n",
    "        ground_truth = row.get(\"Ground Truth\", \"\").strip().lower()\n",
    "\n",
    "        unshuffled_choices_str = row.get(\"Unshuffled Choices\", \"\")\n",
    "        unshuffled_choices = [c.strip() for c in unshuffled_choices_str.split(',')] if unshuffled_choices_str else []\n",
    "\n",
    "        print(f\"\\n---------- {question_id} ----------\")\n",
    "        print(f\"Question: {question_text}\")\n",
    "\n",
    "        results = {\n",
    "            \"Question ID\": question_id,\n",
    "            \"Question\": question_text,\n",
    "            \"Ground Truth\": row.get(\"Ground Truth\", \"\")\n",
    "        }\n",
    "\n",
    "        # --- Szenario 1: Nur Frage (Question Only) ---\n",
    "        answer_qo, latency_qo, len_thinking_qo, len_answer_qo, llm_input_qo, _, _, _ = evaluate_approach(question_text, add_rag_context=False, add_choices=False)\n",
    "        correctness_qo = \"Correct\" if ground_truth in answer_qo.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (QO)\": answer_qo,\n",
    "            \"Duration (QO)\": latency_qo,\n",
    "            \"Length Thinking (QO)\": len_thinking_qo,\n",
    "            \"Length Answer (QO)\": len_answer_qo,\n",
    "            \"Correctness (QO)\": correctness_qo,\n",
    "            \"LLM Input (QO)\": llm_input_qo\n",
    "        })\n",
    "        print(f\"  [QO] Answer: '{answer_qo}' | Correct: {correctness_qo}\")\n",
    "\n",
    "        # --- Szenario 2: Frage + RAG Graph Wissen (RAG) ---\n",
    "        answer_rag, latency_rag, len_thinking_rag, len_answer_rag, llm_input_rag, main_retrieved_node_name_rag, num_retrieved_neighbors_rag, _ = evaluate_approach(question_text, add_rag_context=True, add_choices=False)\n",
    "        correctness_rag = \"Correct\" if ground_truth in answer_rag.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (RAG)\": answer_rag,\n",
    "            \"Duration (RAG)\": latency_rag,\n",
    "            \"Length Thinking (RAG)\": len_thinking_rag,\n",
    "            \"Length Answer (RAG)\": len_answer_rag,\n",
    "            \"Correctness (RAG)\": correctness_rag,\n",
    "            \"Main Retrieved Node Name (RAG)\": main_retrieved_node_name_rag,\n",
    "            \"Num Retrieved Neighbors (RAG)\": num_retrieved_neighbors_rag,\n",
    "            \"LLM Input (RAG)\": llm_input_rag\n",
    "        })\n",
    "        print(f\"  [RAG] Main Node: '{main_retrieved_node_name_rag}', Neighbors: {num_retrieved_neighbors_rag}\")\n",
    "        print(f\"  [RAG] Answer: '{answer_rag}' | Correct: {correctness_rag}\")\n",
    "\n",
    "        # --- Szenario 3: Frage + RAG Graph Wissen + Antwortmöglichkeiten (Choices) ---\n",
    "        answer_choices, latency_choices, len_thinking_choices, len_answer_choices, llm_input_choices, main_retrieved_node_name_choices, num_retrieved_neighbors_choices, choices_sent_to_llm_data = evaluate_approach(question_text, add_rag_context=True, add_choices=True, choices=unshuffled_choices)\n",
    "        correctness_choices = \"Correct\" if ground_truth in answer_choices.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Choices)\": answer_choices,\n",
    "            \"Duration (Choices)\": latency_choices,\n",
    "            \"Length Thinking (Choices)\": len_thinking_choices,\n",
    "            \"Length Answer (Choices)\": len_answer_choices,\n",
    "            \"Correctness (Choices)\": correctness_choices,\n",
    "            \"Main Retrieved Node Name (Choices)\": main_retrieved_node_name_choices,\n",
    "            \"Num Retrieved Neighbors (Choices)\": num_retrieved_neighbors_choices,\n",
    "            \"LLM Input (Choices)\": llm_input_choices,\n",
    "            \"LLM Choices (Choices)\": choices_sent_to_llm_data\n",
    "        })\n",
    "        print(f\"  [Choices] Main Node: '{main_retrieved_node_name_choices}', Neighbors: {num_retrieved_neighbors_choices}\")\n",
    "        print(f\"  [Choices] Choices Sent: '{choices_sent_to_llm_data}'\")\n",
    "        print(f\"  [Choices] Answer: '{answer_choices}' | Correct: {correctness_choices}\")\n",
    "\n",
    "        # --- Szenario 4: Frage + Antwortmöglichkeiten OHNE RAG (Choices No RAG) ---\n",
    "        answer_choices_no_rag, latency_choices_no_rag, len_thinking_choices_no_rag, len_answer_choices_no_rag, llm_input_choices_no_rag, _, _, choices_sent_to_llm_no_rag_data = evaluate_approach(question_text, add_rag_context=False, add_choices=True, choices=unshuffled_choices)\n",
    "        correctness_choices_no_rag = \"Correct\" if ground_truth in answer_choices_no_rag.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Choices No RAG)\": answer_choices_no_rag,\n",
    "            \"Duration (Choices No RAG)\": latency_choices_no_rag,\n",
    "            \"Length Thinking (Choices No RAG)\": len_thinking_choices_no_rag,\n",
    "            \"Length Answer (Choices No RAG)\": len_answer_choices_no_rag,\n",
    "            \"Correctness (Choices No RAG)\": correctness_choices_no_rag,\n",
    "            \"LLM Input (Choices No RAG)\": llm_input_choices_no_rag,\n",
    "            \"LLM Choices (Choices No RAG)\": choices_sent_to_llm_no_rag_data\n",
    "        })\n",
    "        print(f\"  [Choices No RAG] Choices Sent: '{choices_sent_to_llm_no_rag_data}'\")\n",
    "        print(f\"  [Choices No RAG] Answer: '{answer_choices_no_rag}' | Correct: {correctness_choices_no_rag}\")\n",
    "\n",
    "        writer.writerow(results)\n",
    "\n",
    "print(f\"\\nEvaluation complete. Results saved to '{output_csv_filename}'\")"
   ],
   "id": "d2656bb67eae8533",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#####################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################"
   ],
   "id": "eaa22fbf19fcce12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import csv\n",
    "import time\n",
    "import ast # Needed for ast.literal_eval\n",
    "\n",
    "# from neo4j import GraphDatabase\n",
    "# from neo4j_graphrag.embeddings import OllamaEmbeddings\n",
    "# from neo4j_graphrag.retrievers import VectorRetriever\n",
    "# from neo4j_graphrag.llm import OllamaLLM\n",
    "\n",
    "# from os import getenv\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\".env\")\n",
    "# db_uri = getenv(\"db_uri\")\n",
    "# db_name = getenv(\"db_name\")\n",
    "# db_username = getenv(\"db_username\")\n",
    "# db_password = getenv(\"db_password\")\n",
    "# auth = (db_username, db_password)\n",
    "# driver = GraphDatabase.driver(uri=db_uri, auth=auth)\n",
    "# embedder = OllamaEmbeddings(model=\"nomic-embed-text\") # Oder Ihr spezifisches Modell\n",
    "# llm = OllamaLLM(model_name=\"deepseek-r1:1.5b\") # Oder Ihr spezifisches Modell\n",
    "\n",
    "\n",
    "def get_neighborhood(driver, node_id):\n",
    "\n",
    "    with (driver.session(database=db_name) as session):\n",
    "        result = session.run(\"\"\"\n",
    "            MATCH (n)-[r]-(m)\n",
    "            WHERE n.id = $id\n",
    "            RETURN DISTINCT m, type(r) AS rel_type, r.description AS rel_desc\n",
    "        \"\"\", id=node_id)\n",
    "        return [(record[\"m\"], record[\"rel_type\"], record[\"rel_desc\"]) for record in result]\n",
    "\n",
    "def build_question_context(main_node, neighbors):\n",
    "\n",
    "    parts = []\n",
    "    parts.append(\"Best similarity search (the main node) is: \" + f\"\"\"\"{main_node.get('name')}\" of type \"{main_node.get('type')}\". Description of \"{main_node.get('name')}\": {main_node.get('description')}\"\"\")\n",
    "    parts.append(\"\\nThe main node's neighbors are the following nodes:\")\n",
    "\n",
    "    for neighbor, rel_type, rel_desc in neighbors:\n",
    "        parts.append(f\"\"\"\n",
    "+++++ {neighbor.get('name').upper()} +++++\n",
    "Node \"{neighbor.get('name')}\" of type \"{neighbor.get('type')}\". Description of \"{neighbor.get('name')}\": {neighbor.get('description')}\n",
    "The main node is related to \"{neighbor.get('name')}\" via type \"{rel_type}\". This relationship contains the following description: {rel_desc}\"\"\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def evaluate_approach(query_text, add_rag_context=False, add_choices=False, choices=None):\n",
    "\n",
    "    question_context = \"\"\n",
    "    found_node_info = \"N/A\"\n",
    "\n",
    "    if add_rag_context:\n",
    "        retriever = VectorRetriever(driver, \"nodes\", embedder, neo4j_database=db_name)\n",
    "        result = retriever.search(query_text=query_text, top_k=1)\n",
    "\n",
    "        if result.items:\n",
    "            for item in result.items:\n",
    "                dict_item = ast.literal_eval(item.content)\n",
    "                found_node_info = f\"Name='{dict_item.get('name')}', Type='{dict_item.get('type')}', ID='{dict_item.get('id')}'\"\n",
    "\n",
    "                neighbors_of_main_item = get_neighborhood(driver, dict_item[\"id\"])\n",
    "                question_context += build_question_context(dict_item, neighbors_of_main_item)\n",
    "        else:\n",
    "            found_node_info = f\"Warning: No relevant nodes found for query: '{query_text}'\"\n",
    "\n",
    "    full_query_to_llm = query_text\n",
    "\n",
    "    if add_choices and choices:\n",
    "        choices_str = \", \".join(choices)\n",
    "        full_query_to_llm += f\"\\n\\nChoose from the following options: {choices_str}\"\n",
    "\n",
    "    system_instruction = \"\"\n",
    "    if add_rag_context:\n",
    "        system_instruction = question_context\n",
    "        system_instruction += \"\\n\\nAs an IT security expert, based on the provided context and the question, please provide the most accurate answer in English. Start your answer after </think>.\"\n",
    "    else:\n",
    "        system_instruction = \"You are an IT security expert. Please answer the following question in English. Start your answer after </think>.\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    response = llm.invoke(\n",
    "        input=full_query_to_llm,\n",
    "        system_instruction=system_instruction\n",
    "    )\n",
    "    latency = round(time.time() - start_time, 4)\n",
    "\n",
    "    full_response_content = response.content\n",
    "\n",
    "    thinking_part = \"\"\n",
    "    answer_part = full_response_content\n",
    "    if \"</think>\" in full_response_content:\n",
    "        parts = full_response_content.split(\"</think>\", 1)\n",
    "        thinking_part = parts[0].strip()\n",
    "        answer_part = parts[1].strip()\n",
    "\n",
    "    len_thinking = len(thinking_part)\n",
    "    len_answer = len(answer_part)\n",
    "\n",
    "    full_llm_input = f\"System Instruction:\\n{system_instruction}\\n\\nUser Input:\\n{full_query_to_llm}\"\n",
    "\n",
    "    return answer_part, latency, len_thinking, len_answer, full_llm_input, found_node_info\n",
    "\n",
    "\n",
    "# --- Evaluationsskript ---\n",
    "\n",
    "input_csv_filename = \"../AttackSeq-Technique-Test.csv\"\n",
    "output_csv_filename = \"evaluation_results.csv\"\n",
    "\n",
    "fieldnames = [\n",
    "    \"Question ID\",\n",
    "    \"Question\",\n",
    "    \"Retrieved Nodes (RAG)\",\n",
    "    \"Ground Truth\",\n",
    "    \"Answer LLM (Question Only)\", \"Duration (QO)\", \"Length Thinking (QO)\", \"Length Answer (QO)\", \"Correctness (QO)\", \"LLM Input (QO)\",\n",
    "    \"Answer LLM (RAG)\", \"Duration (RAG)\", \"Length Thinking (RAG)\", \"Length Answer (RAG)\", \"Correctness (RAG)\", \"Found Node RAG\", \"LLM Input (RAG)\",\n",
    "    \"Answer LLM (Choices)\", \"Duration (Choices)\", \"Length Thinking (Choices)\", \"Length Answer (Choices)\", \"Correctness (Choices)\", \"Found Node Choices\", \"LLM Input (Choices)\"\n",
    "]\n",
    "\n",
    "print(f\"Starte die Evaluation von '{input_csv_filename}'...\")\n",
    "with open(input_csv_filename, mode=\"r\", newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_csv_filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        question_id = row.get(\"Question ID\", \"\")\n",
    "        question_text = row.get(\"Question\", \"\")\n",
    "        ground_truth = row.get(\"Ground Truth\", \"\").strip().lower()\n",
    "\n",
    "        unshuffled_choices_str = row.get(\"Unshuffled Choices\", \"\")\n",
    "        unshuffled_choices = [c.strip() for c in unshuffled_choices_str.split(',')] if unshuffled_choices_str else []\n",
    "\n",
    "        print(f\"\\n---------- {question_id} ----------\")\n",
    "        print(f\"Question: {question_text}\")\n",
    "\n",
    "        results = {\n",
    "            \"Question ID\": question_id,\n",
    "            \"Question\": question_text,\n",
    "            \"Ground Truth\": row.get(\"Ground Truth\", \"\")\n",
    "        }\n",
    "\n",
    "        # --- Szenario 1: Nur Frage ---\n",
    "        answer_qo, latency_qo, len_thinking_qo, len_answer_qo, llm_input_qo, _ = evaluate_approach(question_text, add_rag_context=False, add_choices=False)\n",
    "        correctness_qo = \"Correct\" if ground_truth in answer_qo.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Question Only)\": answer_qo,\n",
    "            \"Duration (QO)\": latency_qo,\n",
    "            \"Length Thinking (QO)\": len_thinking_qo,\n",
    "            \"Length Answer (QO)\": len_answer_qo,\n",
    "            \"Correctness (QO)\": correctness_qo,\n",
    "            \"LLM Input (QO)\": llm_input_qo\n",
    "        })\n",
    "        print(f\"  [QO] Answer: '{answer_qo}' | Correct: {correctness_qo}\")\n",
    "\n",
    "        # --- Szenario 2: Frage + RAG Graph Wissen ---\n",
    "        answer_rag, latency_rag, len_thinking_rag, len_answer_rag, llm_input_rag, found_node_rag_info = evaluate_approach(question_text, add_rag_context=True, add_choices=False)\n",
    "        correctness_rag = \"Correct\" if ground_truth in answer_rag.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (RAG)\": answer_rag,\n",
    "            \"Duration (RAG)\": latency_rag,\n",
    "            \"Length Thinking (RAG)\": len_thinking_rag,\n",
    "            \"Length Answer (RAG)\": len_answer_rag,\n",
    "            \"Correctness (RAG)\": correctness_rag,\n",
    "            \"Found Node RAG\": found_node_rag_info,\n",
    "            \"LLM Input (RAG)\": llm_input_rag\n",
    "        })\n",
    "        results[\"Retrieved Nodes (RAG)\"] = found_node_rag_info\n",
    "        print(f\"  [RAG] **Retrieved Nodes**: {found_node_rag_info}\")\n",
    "        print(f\"  [RAG] Answer: '{answer_rag}' | Correct: {correctness_rag}\")\n",
    "\n",
    "        # --- Szenario 3: Frage + RAG Graph Wissen + Antwortmöglichkeiten ---\n",
    "        answer_choices, latency_choices, len_thinking_choices, len_answer_choices, llm_input_choices, found_node_choices_info = evaluate_approach(question_text, add_rag_context=True, add_choices=True, choices=unshuffled_choices)\n",
    "        correctness_choices = \"Correct\" if ground_truth in answer_choices.strip().lower() else \"Incorrect\"\n",
    "        results.update({\n",
    "            \"Answer LLM (Choices)\": answer_choices,\n",
    "            \"Duration (Choices)\": latency_choices,\n",
    "            \"Length Thinking (Choices)\": len_thinking_choices,\n",
    "            \"Length Answer (Choices)\": len_answer_choices,\n",
    "            \"Correctness (Choices)\": correctness_choices,\n",
    "            \"Found Node Choices\": found_node_choices_info,\n",
    "            \"LLM Input (Choices)\": llm_input_choices\n",
    "        })\n",
    "\n",
    "        print(f\"  [Choices] **Retrieved Nodes**: {found_node_choices_info}\") # Output retrieved node to console\n",
    "        print(f\"  [Choices] Answer: '{answer_choices}' | Correct: {correctness_choices}\")\n",
    "\n",
    "        writer.writerow(results)\n",
    "\n",
    "print(f\"\\nEvaluation complete. Results saved to '{output_csv_filename}'\")"
   ],
   "id": "5af24fc94fb8a682"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
